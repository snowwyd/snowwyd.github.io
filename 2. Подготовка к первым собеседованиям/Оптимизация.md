---
layout: default
title: Оптимизация производительности
permalink: /interview-prep/go-deep-dive/optimizing/
---

# Цель
---
Написать быстрый код — это искусство. Ты должен знать, как использовать pprof для анализа производительности, находить узкие места, оптимизировать CPU и память.

# Зачем это нужно на собеседовании?
---
Тебя спросят:
- Как профилировать код с pprof?
- Какие есть типы профилей (CPU, memory)?
- Как найти утечки памяти?
- Какие оптимизации дают наибольший эффект?
- Как использовать -race flag?

Это вопросы для Senior уровня, но Middle должен знать основы.

# Теория

### pprof: основы
---
**pprof** — это встроенный профайлер в Go. Он собирает информацию о работе программы и показывает, где она тратит время.

**Импортируем pprof:**
```go
import _ "net/http/pprof"
import "net/http"

func main() {
    go func() {
        http.ListenAndServe("localhost:6060", nil)
    }()
    
    // Теперь профайлер доступен на http://localhost:6060/debug/pprof
}
```

**Доступные профили:**
- `/debug/pprof/profile` — CPU профайл (30 сек)
- `/debug/pprof/heap` — Memory профайл
- `/debug/pprof/goroutine` — Информация о горутинах
- `/debug/pprof/threadcreate` — Созданные потоки

### CPU профилирование
---
**Задача:** Найти, какие функции жрут процессор.

```bash
# Снять CPU профайл на 30 секунд
go tool pprof http://localhost:6060/debug/pprof/profile

# Или с временем
go tool pprof http://localhost:6060/debug/pprof/profile?seconds=5
```

**Interactive режим:**
```
(pprof) top        # Показать топ функций
(pprof) list Add   # Показать код функции Add построчно
(pprof) web        # Открыть граф в браузере (нужен Graphviz)
```

**Пример output (top):**
```
File: main
Type: cpu
Time: Jan 1 2024, 12:00:00
Duration: 30s, Total samples = 30s
Showing top 10 nodes out of 25 (showing 50%)
      flat  flat%   sum%        cum   cum%
      10s 33.33% 33.33%       15s 50.00%  main.heavyComputation
       5s 16.67% 50.00%        5s 16.67%  fmt.Sprintf
       4s 13.33% 63.33%        9s 30.00%  json.Marshal
```

**Что это значит?**
- `flat` — время, потраченное в самой функции
- `cum` — время, включая вызванные функции
- `heavyComputation` потратила 10 сек + 5 сек на вызовы = 15 сек

### Memory профилирование
---
**Задача:** Найти, где происходит утечка памяти.

```bash
# Снять memory профайл
go tool pprof http://localhost:6060/debug/pprof/heap

# Или с фильтром
go tool pprof http://localhost:6060/debug/pprof/heap?debug=1
```

**Interactive режим:**
```
(pprof) top              # Топ аллокаций
(pprof) alloc_space      # Всё, что было выделено
(pprof) alloc_objects    # Количество объектов
(pprof) inuse_space      # Что сейчас в памяти (утечки!)
```

**Пример output:**
```
File: main
Type: alloc_space
Total allocated:       1GB
Showing top 10 nodes out of 30 (showing 80%)
      flat  flat%   sum%        cum   cum%
    500MB 50.00% 50.00%      500MB 50.00%  main.parseJSON
    300MB 30.00% 80.00%      300MB 30.00%  bytes.makeSlice
```

### Goroutine профилирование
---
**Задача:** Найти, не заблокирована ли горутина, не произошла ли утечка.

```bash
curl http://localhost:6060/debug/pprof/goroutine?debug=1
```

**Output:**
```
goroutine 42 [io wait]:
net.(*netFD).read(...)
    /usr/lib/go/src/net/fd_unix.go:123
net.(*conn).Read(...)
    /usr/lib/go/src/net/net.go:163
...
```

**Это показывает:**
- Все активные горутины
- На чём они заблокированы
- Stack trace каждой

### Race detector: -race flag
---
**-race** флаг обнаруживает гонки данных.

```bash
go run -race main.go
go test -race ./...
```

**Пример:**
```
==================
WARNING: DATA RACE
Write at 0x00c000140018 by goroutine 22:
    main.increment()
        /path/to/main.go:12 +0x50

Read at 0x00c000140018 by goroutine 23:
    main.printCounter()
        /path/to/main.go:20 +0x38
```

**Это показывает:** Две горутины обращаются к одной переменной одновременно!

### Практическое профилирование
---

**Способ 1: Programmatically (в коде)**
```go
import (
    "os"
    "runtime/pprof"
)

func main() {
    // Профилировать CPU
    f, _ := os.Create("cpu.prof")
    defer f.Close()
    pprof.StartCPUProfile(f)
    defer pprof.StopCPUProfile()
    
    // ... твой код здесь ...
    
    // Профилировать память
    mf, _ := os.Create("mem.prof")
    defer mf.Close()
    pprof.WriteHeapProfile(mf)
}

// Анализ:
// go tool pprof cpu.prof
// go tool pprof mem.prof
```

**Способ 2: Бенчмарки (встроенные)**
```bash
go test -bench=. -cpuprofile=cpu.prof -memprofile=mem.prof
go tool pprof cpu.prof
```

### Типичные проблемы и решения
---

#### Проблема 1: Много аллокаций
**Symptom:** `alloc_objects` показывает миллионы объектов

**Решение:**
```go
// ❌ Плохо: аллокация в цикле
for i := 0; i < 1000000; i++ {
    buffer := make([]byte, 1024)
    process(buffer)
}

// ✅ Хорошо: переиспользуем buffer
buffer := make([]byte, 1024)
for i := 0; i < 1000000; i++ {
    process(buffer)
}

// ✅ Ещё лучше: object pool
pool := sync.Pool{
    New: func() interface{} {
        return make([]byte, 1024)
    },
}

for i := 0; i < 1000000; i++ {
    buffer := pool.Get().([]byte)
    process(buffer)
    pool.Put(buffer)
}
```

#### Проблема 2: Горутина застряла
**Symptom:** CPU использует 100%, но ничего не происходит

**Решение:**
```bash
curl http://localhost:6060/debug/pprof/goroutine?debug=1 | grep -A 10 "io wait"
```

Это покажет, на чём заблокирована горутина. Возможно, dead lock или infinite loop?

#### Проблема 3: Утечка памяти
**Symptom:** Процесс занимает всё больше памяти

**Решение:**
```go
// Снимаем два профайла с интервалом
pprof.WriteHeapProfile(file1)  // В начале
time.Sleep(1 * time.Minute)
pprof.WriteHeapProfile(file2)  // В конце

// Сравниваем
// go tool pprof -base heap1.prof heap2.prof
```

Это покажет, какие объекты выросли в количестве.

### Оптимизация: практические советы
---

#### 1. Избегай string конкатенации в цикле
```go
// ❌ Плохо: каждый раз новая строка
var result string
for _, item := range items {
    result += item + ","
}

// ✅ Хорошо: используем strings.Builder
var buf strings.Builder
for _, item := range items {
    buf.WriteString(item)
    buf.WriteString(",")
}
result := buf.String()
```

#### 2. Переиспользуй объекты
```go
// ❌ Плохо
func process(data []int) {
    for _, d := range data {
        parsed := parseJSON(string(d))
        // ...
    }
}

// ✅ Хорошо
parser := json.NewDecoder(...)
for _, d := range data {
    parser.Decode(...)
}
```

#### 3. Используй буферизованные каналы
```go
// ❌ Небуферизованный канал блокирует
results := make(chan int)
for i := 0; i < 1000; i++ {
    go func(i int) {
        results <- i  // Может заблокироваться!
    }(i)
}

// ✅ Буферизованный
results := make(chan int, 1000)
```

# Правило для собеседования
---
**Когда спрашивают про оптимизацию, отвечай:**

"Я использую pprof для профилирования. Сначала берусь за CPU профайл, чтобы найти самые горячие функции.

Затем ищу утечки памяти через memory профайл — инuse_space показывает, что сейчас в памяти.

-race флаг помогает найти гонки данных. Я всегда запускаю код с этим флагом во время разработки.

Оптимизация начинается с измерения, а не с угадывания. Я пишу бенчмарки и смотрю на результаты pprof перед тем, как что-то менять."

---

**[← Назад к Go углубленно](../)**
