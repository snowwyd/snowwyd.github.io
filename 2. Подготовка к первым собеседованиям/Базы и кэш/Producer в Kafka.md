---
layout: default
title: Producer - глубокое понимание
permalink: /interview-prep/databases-cache/kafka/producer/
---

# Цель
---
Производитель — это ваш "отправитель". На собеседовании вас спросят про гарантии доставки, партиционирование, батчинг, сжатие. Давайте разберемся во всех нюансах.

# Материалы
---
## Как Producer выбирает раздел?
---

Это один из самых важных вопросов, который спрашивают на собеседованиях.

**Если у вас есть ключ (key)**:
```
номер_раздела = хеш(ключ) % количество_разделов
```

Все сообщения с одинаковым ключом попадут в один и тот же раздел. Это гарантирует порядок обработки для одного "объекта".

**Пример**:
- Topic `заказы` имеет 5 разделов
- Вы отправляете сообщение с ключом `пользователь-123`
- `хеш("пользователь-123") % 5 = 2` → сообщение идет в раздел 2

Это значит, что все заказы одного пользователя будут в одном разделе и обработаны по порядку.

**Если ключа нет (key=null)**:
- Версия < 3.0: Round-robin по разделам
- Версия >= 3.0: Липкий распределитель (батчит сообщения в один раздел, потом переходит на следующий)

## Конфигурация Producer
---

### acks (Подтверждения)

Это самая важная конфигурация. Она контролирует, когда производитель считает, что сообщение успешно отправлено.

**acks=0**
- Производитель не ждет никакого подтверждения
- Максимальная производительность, минимальная надежность
- Может потерять сообщения если брокер падает
- Используется когда потери данных некритичны (логирование)

**acks=1** (по умолчанию)
- Производитель ждет подтверждения только от лидера брокера
- Лидер добавил в свой журнал, но может не разреплицировать на followers
- Если лидер упадет до репликации, сообщение потеряется
- Среднее соотношение надежности и производительности

**acks=all** (или acks=-1)
- Производитель ждет, пока все синхронизированные копии (ISR) подтвердят
- Максимальная надежность, но медленнее
- Гарантирует, что сообщение не потеряется
- Используется для критичных данных (платежи, заказы)

**На собеседовании**:
> "Какой acks выбрать для платежной системы?"
> Ответ: "acks=all, потому что потеря платежа недопустима. Медленнее? Ладно, платежи критичнее чем скорость."

### retries и retry.backoff.ms

**retries**: Сколько раз производитель попробует отправить сообщение при ошибке.
- По умолчанию: Integer.MAX_VALUE в новых версиях
- Означает "бесконечные попытки пока не истечет таймаут"

**retry.backoff.ms**: Задержка между попытками.
- По умолчанию: 100ms
- Экспоненциальная задержка может быть полезна

**На практике**:
```go
// повтор с задержкой помогает при временных сбоях сети
повторов := 3
for попытка := 0; попытка < повторов; попытка++ {
    ошибка := производитель.Отправить(сообщение)
    if ошибка == nil {
        break
    }
    time.Sleep(time.Duration(100 * math.Pow(2, float64(попытка))) * time.Millisecond)
}
```

### Параметры батчинга

**batch.size** (байты)
- Размер буфера для батчинга сообщений
- По умолчанию: 16KB
- Производитель накапливает сообщения в буфер, потом отправляет одним пакетом
- Больший размер = меньше сетевых запросов = выше throughput, выше latency

**linger.ms**
- Максимальное время ожидания перед отправкой батча
- По умолчанию: 0
- Если батч не заполнился, но прошло linger.ms миллисекунд, отправить все равно
- Пример: batch.size=1000, но у вас только 500 сообщений в секунду?
  - Без linger: отправляется сразу (latency низкая)
  - С linger=100ms: ждет еще 100ms, может собрать еще сообщений

**Компромисс**: Latency против Throughput
- Высокий latency, высокий throughput: большой batch.size, большой linger.ms
- Низкий latency: маленький batch.size, маленький linger.ms

### Сжатие

**compression.type**: none, snappy, lz4, zstd
- Сжимает данные перед отправкой
- Уменьшает сетевой трафик и дисковое пространство
- Требует CPU для сжатия/распаковки

**Когда использовать**:
- Высокая сетевая нагрузка? → snappy или lz4
- Максимальное сжатие? → zstd
- Низкая CPU загрузка важнее? → none

## Максимум одновременных запросов

**max.in.flight.requests.per.connection**
- Сколько неподтвержденных запросов может быть одновременно
- По умолчанию: 5
- Влияет на упорядочение сообщений!

**Важный момент**: Если max.in.flight > 1 И происходит ошибка на одном из запросов, потом проходят повторы, может нарушиться порядок сообщений.

Решение:
```go
// Для гарантии порядка
max.in.flight.requests = 1
```

## Идемпотентность Producer

**idempotence=true**
- Производитель автоматически получает ID и порядковый номер последовательности
- Kafka не сохранит дублирующееся сообщение
- Гарантирует "ровно один раз" семантику per производитель per раздел

Как это работает:
1. Производитель отправляет сообщение #1 с producer_id=123, последовательность=1
2. Брокер получил, но подтверждение потерялось в сети
3. Производитель делает повтор, отправляет снова
4. Брокер видит: "такой producer_id и последовательность уже есть", не добавляет дубль

**На практике**: Включайте `idempotence=true` в production (есть небольшое увеличение затрат).

## Типичные вопросы собеседования
---

**В: Можем ли мы потерять сообщение с acks=all?**
О: Да, если количество синхронизированных копий упало ниже min.insync.replicas. Конфигурация min.insync.replicas=2 означает, что нужно минимум 2 синхронизированные копии. Если их становится меньше, производитель получит ошибку.

**В: Какое максимальное размер сообщения в Kafka?**
О: По умолчанию 1MB (byte.message.max.bytes), но можно увеличить. На практике большие сообщения деградируют производительность — лучше использовать внешнее хранилище (S3) и отправлять ссылку в Kafka.

**В: Что если производитель отправляет 10000 сообщений в секунду, но потребитель может обработать только 1000?**
О: Kafka буферирует сообщения на диске. Потребитель просто отстает (отставание потребителя растет). Это нормально, когда Kafka заполнится, производитель может получить ошибку или ждать.

**В: Как гарантировать ровно один раз доставку?**
О: Включить idempotence=true на производителе. Это гарантирует что одно сообщение не будет сохранено дважды.

---

**[← Назад к Kafka](../)**