---
layout: default
title: Kafka Streams
permalink: /interview-prep/databases-cache/kafka/streams/
---

# Цель
---
Если обычный потребитель просто читает сообщения, то **Kafka Streams** позволяет обрабатывать их как потоки данных: фильтровать, преобразовывать, объединять, агрегировать.

Думайте о Kafka Streams как о **Apache Spark**, но встроенном в Kafka и работающем в реальном времени.

# Материалы
---
## КПоток, КТаблица, ГлобальнаяКТаблица
---

### КПоток — неограниченный поток событий

```go
// Это как Consumer, но с функциональными операциями
// Каждое сообщение — отдельное событие

// Пример: поток заказов
builder := &topology.Builder{}
source := builder.AddSource(topology.AutoOffsetResetEarliest, "заказы")
```

**Характеристики**:
- Каждое сообщение имеет значение
- Нет "последнего" состояния для ключа
- Без состояния (обычно)
- Бесконечный поток

**Операции**:
```
map()       - преобразовать каждое сообщение
filter()    - оставить только нужные
flatMap()   - развернуть в несколько сообщений
branch()    - разделить на несколько потоков
peek()      - посмотреть и продолжить
```

### КТаблица — таблица (состояние)

```go
// КТаблица = последнее значение для каждого ключа
// Это как view базы данных

// Пример: таблица пользователей
// КТаблица хранит последнее состояние каждого пользователя
```

**Характеристики**:
- Для каждого ключа хранится последнее значение
- Обновления — это последовательность изменений
- С состоянием
- Может использовать RocksDB для сохранения состояния

**Когда использовать КТаблицу**:
- Таблица пользователей (последний профиль)
- Счета (баланс)
- Конфигурация (последние параметры)

### ГлобальнаяКТаблица — глобальная таблица

```go
// Копия КТаблицы на КАЖДОМ экземпляре потока обработки
// Используется для объединений
```

Отличие от КТаблицы:
- Все процессы имеют полную копию
- Хороший для небольших справочных данных (страны, валюты)
- Плохо для больших таблиц (слишком много памяти)

## Операции без состояния
---

```go
// Фильтр: оставить только заказы больше $100
заказы
    .Filter((ключ, значение) -> значение.сумма > 100)
    .To("большие-заказы")

// Карта: преобразовать формат
заказы
    .Map((ключ, значение) -> (ключ, преобразоватьВDTO(значение)))
    .To("заказы-преобразованные")

// ПлоскаяКарта: развернуть в несколько сообщений
заказы
    .FlatMap((ключ, заказ) -> {
        // Один заказ → много товаров
        return заказ.товары.map(товар -> (заказ.id, товар))
    })
    .To("товары-заказа")
```

## Операции с состоянием (Агрегирования)
---

### Подсчет

```go
// Считаем заказы по пользователю_id
заказы
    .GroupByKey()
    .Count()
    .ToStream()
    .To("количество-заказов-пользователя")

// Результат: пользователь_123 → 5 заказов, пользователь_456 → 3 заказа
```

### Сумма

```go
// Считаем сумму покупок по пользователю_id
заказы
    .GroupByKey()
    .Aggregate(
        () -> 0,  // инициализатор
        (ключ, значение, агрегат) -> агрегат + значение.сумма  // агрегатор
    )
    .ToStream()
    .To("сумма-покупок-пользователя")
```

### Пользовательское агрегирование

```go
// Средний размер заказа по пользователю
заказы
    .GroupByKey()
    .Aggregate(
        () -> new СостояниеАгрегата(0, 0), // количество, сумма
        (ключ, значение, агр) -> {
            агр.сумма += значение.сумма
            агр.количество++
            return агр
        }
    )
    .MapValues(агр -> агр.сумма / агр.количество) // среднее
    .ToStream()
    .To("средний-размер-заказа-пользователя")
```

## Объединения (Joins)
---

### КПоток объединить КПоток

```go
// Объединяем заказы и платежи
// Но: только совпадения по времени в временном окне!

KStream<String, Заказ> заказы = ...
KStream<String, Платеж> платежи = ...

заказы
    .join(
        платежи,
        (заказ, платеж) -> new ЗаказСПлатежом(заказ, платеж),
        JoinWindows.of(Duration.ofSeconds(5)), // окно 5 сек
        StreamJoined.with(Serdes.String(), заказSerde, платежSerde)
    )
    .To("заказы-с-платежами")
```

### КПоток объединить КТаблица

```go
// Объединяем события со справочными данными
// ЛЕВАЯ: события (КПоток), ПРАВАЯ: таблица (КТаблица)

KStream<String, Заказ> заказы = ...
KTable<String, Пользователь> пользователи = ... // кэшированные данные

заказы
    .leftJoin(
        пользователи,
        (заказ, пользователь) -> new ЗаказСПользователем(заказ, пользователь)
    )
    .To("заказы-с-пользователями")
```

**Особенность**: Для каждого нового заказа смотрим ТЕКУЩЕЕ значение в КТаблице.

### КПоток объединить ГлобальнаяКТаблица

```go
// Похоже на КТаблица объединение, но используем ГлобальнаяКТаблица
// ГлобальнаяКТаблица = полная копия везде (для малых наборов данных)

заказы
    .leftJoin(
        глобальныеСтраны,
        (ключ, заказ) -> заказ.код_страны, // как объединять
        (заказ, страна) -> new ЗаказСоСтраной(заказ, страна)
    )
    .To("заказы-со-страной")
```

## Окна (Временные окна)
---

```go
// Агрегировать заказы ПО ВРЕМЕНИ

заказы
    .GroupByKey()
    .WindowedBy(TimeWindows.of(Duration.ofMinutes(5))) // 5-минутные окна
    .Count()
    .ToStream()
    .To("заказы-за-5-минут")

// Результат: [10:00-10:05] пользователь_123 → 3 заказа, [10:05-10:10] пользователь_123 → 2 заказа
```

**Типы окон**:
- **Переворачивающееся**: [10:00-10:05], [10:05-10:10] — не пересекаются
- **Прыгающее**: [10:00-10:05], [10:02-10:07] — пересекаются
- **Сессия**: [10:00-10:15] если была активность, потом пауза, потом новое окно

## Типичные вопросы собеседования
---

**В: Чем КПоток отличается от Consumer?**
О: Consumer — это просто чтение сообщений. КПоток — это функциональная обработка потока (фильтр, карта, агрегат). КПоток это более высокий уровень абстракции.

**В: Как Kafka Streams хранит состояние для агрегирований?**
О: В локальном RocksDB. Это есть на каждом экземпляре. Для отказоустойчивости состояние может быть реплицировано в журнал изменений Kafka темы.

**В: Может ли КПоток объединение узнать что нет совпадения в другом потоке?**
О: Нет (с inner join). Используйте leftJoin или outerJoin. leftJoin отправит сообщение даже если ничего не найдено в правом потоке (как LEFT OUTER JOIN в SQL).

**В: Как масштабировать приложение Kafka Streams?**
О: Добавьте больше экземпляров приложения с одинаковым application.id. Kafka автоматически распределит разделы между ними как группа потребителей.

---

**[← Назад к Kafka](../)**