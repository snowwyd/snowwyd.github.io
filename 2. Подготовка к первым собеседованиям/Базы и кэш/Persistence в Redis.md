---
layout: default
title: "Persistence: RDB и AOF"
permalink: /interview-prep/databases-cache/redis/persistence/
---

# Цель
---
По умолчанию, Redis хранит всё в памяти. Если Redis упадёт, все данные потеряются. Persistence механизмы решают эту проблему, но создают trade-offs между скоростью и надёжностью.

# Материалы
---
## Базовая проблема

```
Сценарий: Production crash
1. Redis работал отлично
2. Сервер перезагрузился
3. Redis не помнит никаких данных (всё было в памяти)
4. Приложение сломалось без данных
```

Решение: сохранять данные на диск.

## Опция 1: No Persistence (По умолчанию)
---

```redis
# Ничего не сохраняется на диск
save ""
```

**Плюсы**: Максимальная скорость  
**Минусы**: Потеря данных при crash  

**Когда использовать**: Чистый cache где потеря OK.

## Опция 2: RDB (Redis Database Snapshots)
---

Сохраняет полный снимок памяти в один файл в определённые моменты.

### Как это работает:

```
Time: 00:00 → Redis делает снимок всей памяти → dump.rdb
Time: 01:00 → Ещё один снимок → dump.rdb (перезаписывается)
Time: 02:00 → Ещё один → dump.rdb

Если Redis упадёт в 00:30:
Восстанавливаем из снимка от 00:00 → потеря 30 минут данных
```

### Конфигурация:

```redis
# redis.conf
save 900 1          # Save if 1 key changed in 900 seconds
save 300 10         # Save if 10 keys changed in 300 seconds
save 60 10000       # Save if 10000 keys changed in 60 seconds
```

Или через команду:

```redis
SAVE                # Синхронно сохранить (блокирует!)
BGSAVE              # Асинхронно (фоновый процесс)
LASTSAVE            # Когда был последний save?
```

### Процесс BGSAVE:

```
1. Redis создаёт fork (дочерний процесс)
2. Дочерний процесс пишет на диск
3. Основной процесс продолжает обработку запросов
```

**Плюсы**:
- ✅ Быстрый процесс save (особенно BGSAVE)
- ✅ Компактный файл
- ✅ Быстрое восстановление (просто загрузить файл)

**Минусы**:
- ❌ Потеря данных между snapshots
- ❌ fork может быть дорогой операцией (если Redis большой)

**Когда использовать**: Когда OK потерять последние минуты.

## Опция 3: AOF (Append Only File)
---
Логирует ВСЕ write операции в файл. Потом replay'ит их при восстановлении.

### Как это работает:

```
SET key1 value1  → записать в AOF
SET key2 value2  → записать в AOF
INCR counter     → записать в AOF

При восстановлении:
Прочитать AOF → SET key1 value1 → SET key2 value2 → INCR counter
```

### Конфигурация:

```redis
# redis.conf
appendonly yes
appendfilename "appendonly.aof"
appendfsync always      # fsync после каждой операции (медленно!)
# OR
appendfsync everysec    # fsync каждую секунду (хорошо)
# OR
appendfsync no          # OS сам решает когда fsync
```

### Процесс:

```redis
SET key "value"
# Redis: логирует в AOF
# Клиент: получает "OK"

# В файле:
*3\r\n$3\r\nSET\r\n$3\r\nkey\r\n$5\r\nvalue\r\n
```

### AOF Rewrite:

Со временем AOF файл становится огромным. Redis может переписать его:

```redis
BGREWRITEAOF        # Асинхронно переписать AOF
```

```
До rewrite:
SET counter 0
INCR counter  # 1
INCR counter  # 2
INCR counter  # 3
... (миллион операций)
INCR counter  # 1000000

После rewrite:
SET counter 1000000   # только финальное состояние!
```

**Плюсы**:
- ✅ Максимальная безопасность (потеря секунды данных)
- ✅ Можно читать AOF файл (просто текст/RESP)
- ✅ Можно вручную восстанавливать

**Минусы**:
- ❌ AOF файл больше чем RDB
- ❌ Медленнее восстановление
- ❌ Может замедлить Redis если appendfsync always

**Когда использовать**: Критичные данные где потеря недопустима.

## Опция 4: RDB + AOF
---
Комбинируем оба подхода:

```redis
# redis.conf
save 900 1
appendonly yes
appendfsync everysec
```

**Как это работает**:
- Пишем в AOF постоянно (безопасно)
- Периодически делаем RDB snapshots (для быстрого восстановления)

**При восстановлении**:
1. Загружаем последний RDB snapshot
2. Replay'им AOF операции что были после snapshot'а

**Плюсы**: 
- ✅ Безопасность + скорость
- ✅ Гибкий выбор

**Минусы**:
- ❌ Два файла для manage'а
- ❌ Больше disk I/O


## Сравнение
---

| Аспект | RDB | AOF | RDB+AOF |
|--------|-----|-----|---------|
| **Потеря данных** | До минут | Секунды | Очень мало |
| **Скорость восстановления** | Быстро | Медленно | Хорошо |
| **Размер файла** | Компактный | Большой | Средний |
| **Надёжность** | Средняя | Высокая | Высокая |
| **Disk I/O** | Низкий | Высокий | Средний |


## Практический выбор
---

```
Какой use-case?

├─ Cache (потеря OK)?
│  └─ No persistence (save "")

├─ Session store (потеря OK)?
│  └─ RDB (save 60 10000)

├─ Счётчики, analytics (потеря минут OK)?
│  └─ RDB (save 300 1000)

├─ Финансовые данные (потеря НЕДОПУСТИМА)?
│  └─ AOF с appendfsync everysec

├─ Критичные + нужна скорость?
│  └─ RDB + AOF
```


## Real-world issues
---

### Issue 1: RDB fork занимает слишком много памяти

Когда Redis делает BGSAVE, временно нужна дополнительная память для fork.

```
Если Redis использует 5GB, fork может потребовать ещё 5GB!
Если на сервере всего 8GB → OOM!
```

**Решение**: Мониторь memory, убедись что есть свободное место.

### Issue 2: AOF слишком большой

```
AOF файл вырос до 100GB
Восстановление занимает часы
```

**Решение**: Запустить BGREWRITEAOF чаще.

### Issue 3: Потеря данных между RDB snapshots

```
RDB save 300 1000  # каждые 5 минут
Redis упал в минуту после save
Потеряли 4 минуты данных
```

**Решение**: Использовать AOF + RDB.


## Файлы и их расположение
---

```
# Обычно в рабочей директории Redis:
dump.rdb              # RDB файл
appendonly.aof        # AOF файл
```

Можешь изменить в конфиге:

```redis
# redis.conf
dir /var/lib/redis    # директория для файлов
```

## Мониторинг persistence
---

```redis
INFO persistence

# Output:
loading: 0
rdb_changes_since_last_save: 150
rdb_bgsave_in_progress: 0
rdb_last_save_time: 1234567890
rdb_last_bgsave_status: ok
aof_enabled: 1
aof_rewrite_in_progress: 0
aof_last_bgsave_status: ok
```

## Best Practices
---
1. **Выбери persistence стратегию** основываясь на use-case
2. **Мониторь RDB/AOF файлы** (размер, время создания)
3. **Убедись что на диске достаточно места**
4. **Тестируй восстановление** (не в production!)
5. **Для критичных данных используй AOF + RDB**
6. **Backup'и файлы** (copy to separate storage)

## Следующие шаги
---
Теперь когда ты понимаешь persistence, пора разобраться с репликацией — как иметь несколько Redis instance'ов синхронизированными между собой.

---

**[← Назад к Redis](../)**