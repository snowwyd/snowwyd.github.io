---
layout: default
title: Кэширование и Cache Patterns
permalink: /interview-prep/databases-cache/redis/caching/
---

# Цель
---
Научиться выбирать правильный паттерн кэширования для конкретной задачи. На собеседовании про Redis 80% вопросов будут про кэширование. И вопросы не просто "Что такое кэш?" — они будут про то какой паттерн выбрать, как избежать стейл данных, как обработать cache miss, и как не дропить бд запросами от cache miss'ей.

# Материалы
---
## Базовая проблема
---

```
Приложение                БД (медленно)
     ↓                       ↓
  GET user:1000      → SELECT * FROM users WHERE id=1000
                      ← (5-10ms) вернуть результат
  ← (5-10ms)
```

**Проблема**: Каждый запрос идёт в БД. БД может обработать 1000-10000 запросов в секунду, но не миллионы. Когда трафик растёт, БД становится узким местом.

**Решение**: Кэш. Вместо хранения данных только в БД, храним их и в Redis.

```
Redis (быстро, памяти)     БД (медленно, диск)
     ↑ ← GET user:1000 ↓
```

Теперь GET user:1000 из Redis — это микросекунды вместо миллисекунд.

## 1. Cache-Aside (Lazy Loading)
---
Самый простой и самый популярный паттерн.

### Как работает:

```
Клиент: "Дай мне user:1000"

1. Проверяем Redis
   GET user:1000
   
   Если есть (Cache HIT)
   ├─ вернуть результат клиенту
   └─ финиш ✓
   
   Если нет (Cache MISS)
   ├─ идём в БД
   │  SELECT * FROM users WHERE id=1000
   ├─ результат кэшируем
   │  SET user:1000 "{...}" EX 3600
   └─ вернуть клиенту
```

### Код (на Go):

```go
func GetUser(userID int64) (User, error) {
    // Шаг 1: Check cache
    cached := redis.Get(fmt.Sprintf("user:%d", userID))
    if cached != nil {
        return parseUser(cached), nil
    }
    
    // Шаг 2: Cache miss - go to DB
    user := db.GetUser(userID)
    if user == nil {
        return nil, ErrNotFound
    }
    
    // Шаг 3: Store in cache
    jsonData := json.Marshal(user)
    redis.Set(fmt.Sprintf("user:%d", userID), jsonData, 3600) // 1 hour TTL
    
    return user, nil
}
```

### Плюсы:

- ✅ Простой код
- ✅ Гибкий TTL (можешь менять когда кэш истекает)
- ✅ Автоматически удаляет стейл данные (через TTL)

### Минусы:

- ❌ **Cache Stampede**: Если кэш истёк и много запросов пришло одновременно, все пойдут в БД
- ❌ Приложение отвечает за синхронизацию данных
- ❌ **Stale data**: Если данные в БД обновились, кэш всё ещё старый (пока не истекла TTL)

### Когда использовать:

- Read-heavy операции
- Когда OK если данные немного стейл (например, profile юзера)
- Когда TTL достаточно для invalidation

### Cache Stampede — как избежать:

```go
// ❌ Плохо - много запросов в БД одновременно
if redis.Get("user:1000") == nil {
    // 1000 goroutines приходят сюда одновременно!
    user := db.GetUser(1000) // 1000 запросов в БД!
}

// ✅ Хорошо - используем мьютекс или "probabilistic early expiration"
const CACHE_TTL = 3600
const EARLY_EXPIRATION_FACTOR = 0.1 // 10% chance

if redis.Get("user:1000") == nil {
    // Вероятностное обновление до истечения TTL
    if rand.Float64() < EARLY_EXPIRATION_FACTOR {
        // только один goroutine обновит кэш
        user := db.GetUser(1000)
        redis.Set("user:1000", user, CACHE_TTL)
    }
}
```

## 2. Read-Through
---
Кэш сам тянет данные из БД.

### Как работает:

```
Клиент → Redis → БД
         (если нет в кэше)
```

Отличие от Cache-Aside: **приложение не знает про БД**. Всё взаимодействие с Redis, Redis уже знает как получить данные из БД если их нет.

### Обычно реализуется на уровне Redis Cluster или специального слоя:

```go
// Это не настоящий Redis. Redis не может сам ходить в БД.
// Это фактически то же что Cache-Aside но логика в другом слое.

// Redis Module или прокси может реализовать Read-Through:
// RedisCluster → Load из БД если miss
```

### Плюсы:

- ✅ Приложение проще (не знает про БД)
- ✅ Логика кэширования централизована

### Минусы:

- ❌ Нужен специальный компонент (Redis Module, прокси, etc.)
- ❌ Дороже в maintenance

### Когда использовать:

- Когда хочешь декаплировать приложение от БД
- Большие системы с множеством клиентов

## 3. Write-Through
---
Данные пишутся в БД **синхронно** через кэш.

### Как работает:

```
Клиент: "Сохрани user:1000"

1. Redis: SET user:1000 "{...}"
2. Redis ждёт пока БД обновится
3. БД: UPDATE users SET ... WHERE id=1000
4. Ответ клиенту "ОК"
```

### Код:

```go
func UpdateUser(userID int64, newData User) error {
    // Шаг 1: Write to cache first
    jsonData := json.Marshal(newData)
    if err := redis.Set(fmt.Sprintf("user:%d", userID), jsonData, 3600); err != nil {
        return err
    }
    
    // Шаг 2: Write to DB
    if err := db.UpdateUser(userID, newData); err != nil {
        // ❌ Проблема! Данные в Redis но не в БД
        // Нужна логика для компенсации
        redis.Del(fmt.Sprintf("user:%d", userID))
        return err
    }
    
    return nil
}
```

### Плюсы:

- ✅ Данные в кэше и БД всегда синхронны
- ✅ Нет stale data

### Минусы:

- ❌ **Медленно**: пишешь в две системы, ждёшь обе
- ❌ **Dual Write проблема**: Если Redis успешно, а БД упадёт - рассинхрон!
- ❌ Повышенная latency: write становится столько же медленным как самый медленный компонент (БД)

### Когда использовать:

- Критичные данные где consistency важнее speed'а
- Финансовые системы, платежи

## 4. Write-Behind (Write-Back)
---
Данные пишутся в Redis **асинхронно**, потом в БД.

### Как работает:

```
Клиент: "Сохрани user:1000"

1. Redis: SET user:1000 "{...}" → ✓ OK (быстро!)
2. Асинхронный job/background process
3. В итоге: БД обновляется (потом)
```

### Код:

```go
func UpdateUserAsync(userID int64, newData User) error {
    // Шаг 1: Write to cache immediately
    jsonData := json.Marshal(newData)
    redis.Set(fmt.Sprintf("user:%d", userID), jsonData, 3600)
    
    // Шаг 2: Queue async job for DB update
    jobQueue.Enqueue(UpdateUserJob{
        UserID: userID,
        Data: newData,
    })
    
    return nil
}

// Background worker
func ProcessUpdateJob(job UpdateUserJob) {
    // Эта работает в фоне
    err := db.UpdateUser(job.UserID, job.Data)
    if err != nil {
        // Retry logic, DLQ, etc.
        log.Error("Failed to update user", err)
    }
}
```

### Плюсы:

- ✅ **Быстро**: возвращаешь ответ сразу
- ✅ Приложение responsive
- ✅ Может батчить обновления для БД

### Минусы:

- ❌ **Потеря данных**: Если Redis упадёт до того как job обновит БД
- ❌ **Eventual consistency**: Приложение видит новые данные но БД ещё нет
- ❌ **Сложность**: нужно управлять job queue, retries, etc.

### Когда использовать:

- Analytics, logs, metrics (данные не критичны)
- Когда speed важнее чем immediate consistency
- Can tolerate eventual consistency

## 5. Cache Invalidation
---
Как избежать stale data? Есть три способа:

### 5.1 Time-based invalidation

```redis
SET user:1000 "{...}" EX 3600    # удалится через час
```

**Плюсы**: простой  
**Минусы**: стейл data между обновлением и expiration

### 5.2 Event-based invalidation

При обновлении данных, явно удаляем из кэша:

```go
func UpdateUser(userID int64, newData User) error {
    // Обновляем в БД
    err := db.UpdateUser(userID, newData)
    if err != nil {
        return err
    }
    
    // Удаляем из кэша (будет перезагружен на следующий GET)
    redis.Del(fmt.Sprintf("user:%d", userID))
    
    return nil
}
```

**Плюсы**: нет stale data  
**Минусы**: нужно помнить invalidate везде где обновляется

### 5.3 Hybrid (обычно лучше)

```redis
SET user:1000 "{...}" EX 3600    # TTL для emergencies
# + явно delete при обновлении
```

## Real-world issues
---
### Issue 1: Cache Stampede под нагрузкой

Решение через "probabilistic early expiration":

```go
func GetUserWithStampedeProtection(userID int64) (User, error) {
    key := fmt.Sprintf("user:%d", userID)
    
    // Получаем данные И TTL
    data := redis.Get(key)
    ttl := redis.TTL(key)
    
    if data == nil {
        // Miss - обновляем
        return updateCacheFromDB(userID)
    }
    
    // Если кэш истекает через <10% его оставшегося времени
    // обновляем в фоне
    const EARLY_REFRESH_FACTOR = 0.1
    originalTTL := 3600 // assume 1 hour
    if ttl < int(float64(originalTTL)*EARLY_REFRESH_FACTOR) {
        go updateCacheFromDB(userID) // async refresh
    }
    
    return parseUser(data), nil
}
```

### Issue 2: Memory exhaustion

```redis
# Когда Redis заполнится, нужна eviction policy
CONFIG SET maxmemory 1gb
CONFIG SET maxmemory-policy allkeys-lru    # удалять least recently used
```

### Issue 3: Monitoring cache effectiveness

```go
// В приложении отслеживай:
hits := 0
misses := 0

for {
    if cache.Get(key) != nil {
        hits++
    } else {
        misses++
    }
    
    hitRate := float64(hits) / float64(hits+misses)
    if hitRate < 0.7 { // If <70% hit rate
        log.Warn("Low cache hit rate:", hitRate)
    }
}
```

## Сравнение паттернов
---

| Паттерн | Complexity | Speed | Consistency | Use Case |
|---------|-----------|-------|-------------|----------|
| Cache-Aside | Low | Good | Eventually | General read-heavy |
| Read-Through | Medium | Good | Eventually | Centralized cache |
| Write-Through | High | Slow | Strong | Critical data |
| Write-Behind | High | Fast | Eventual | Analytics, logs |

## Decision tree для выбора паттерна
---

```
Что нужно?

├─ Read-heavy без частых обновлений?
│  └─ Cache-Aside + TTL

├─ Нужна гарантия что data в cache и BD в sync?
│  └─ Write-Through (если speed OK)

├─ Очень важна speed при writes?
│  └─ Write-Behind (если consistency может быть eventual)

├─ Хочу декаплировать приложение от БД?
│  └─ Read-Through (нужен специальный слой)
```

## Следующие шаги
---
Теперь когда ты понимаешь кэширование, пора разобраться с тем, как гарантировать atomicity нескольких операций. Это приводит нас к транзакциям и Lua scripting.

---

**[← Назад к Redis](../)**