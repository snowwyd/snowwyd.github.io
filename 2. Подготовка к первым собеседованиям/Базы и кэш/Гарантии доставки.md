---
layout: default
title: Гарантии доставки сообщений
permalink: /interview-prep/databases-cache/kafka/delivery-guarantees/
---

# Цель
---
Это может быть самый важный вопрос на собеседовании: "Какие гарантии доставки дает Kafka?"

Ответ: "Это зависит от конфигурации производителя и потребителя". Давайте разберемся во всех комбинациях.

# Материалы
---
## Три типа гарантий
---
### 1. Максимум один раз (at-most-once)

**Определение**: Каждое сообщение доставляется 0 или 1 раз. Может быть потеря.

**Как достичь**:
```go
// Производитель
писатель := &kafka.Writer{
    Addr:   kafka.TCP("localhost:9092"),
    Topic:  "события",
    Acks:   0, // Не ждем подтверждения!
}

// Потребитель
читатель := kafka.NewReader(kafka.ReaderConfig{
    GroupID: "группа1",
    // ... автофиксирование включено (по умолчанию)
})
```

**Когда произойдет потеря**:
- Производитель отправил, но брокер упал перед сохранением ДО репликации
- Потребитель обработал, но упал ДО фиксирования смещения

**Где это использовать**:
- Метрики, логирование, аналитика где небольшие потери некритичны
- Высокочастотная торговля где скорость > точность

**На собеседовании**:
> "Используется для неважных данных. Примеры: счетчик нажатий, анонимная аналитика."

### 2. Минимум один раз (at-least-once)

**Определение**: Каждое сообщение доставляется 1+ раз. Может быть дублирование.

**Как достичь**:
```go
// Производитель
писатель := &kafka.Writer{
    Addr:   kafka.TCP("localhost:9092"),
    Topic:  "события",
    Acks:   1, // Ждем подтверждения от лидера (по умолчанию)
}

// Потребитель
читатель := kafka.NewReader(kafka.ReaderConfig{
    GroupID: "группа1",
    // автофиксирование (по умолчанию)
})
```

**Когда произойдет дублирование**:
- Производитель отправил сообщение, лидер добавил, но подтверждение потерялось
- Производитель делает повтор, отправляет снова
- Потребитель обработал сообщение, но упал ДО фиксирования

**Как обработать дублирование**:
```go
// Идемпотентность в слое приложения
обработанныеСообщения := make(map[string]bool)

сообщение, ошибка := читатель.ReadMessage(ctx)
идентификаторСообщения := string(сообщение.Value) // Предполагаем, что это ID

if обработанныеСообщения[идентификаторСообщения] {
    // Уже видели это сообщение, пропустить
    continue
}

// Обработать и сохранить в БД атомарно
обработатьСообщениеИСохранитьID(сообщение, идентификаторСообщения)
обработанныеСообщения[идентификаторСообщения] = true
```

**Где это использовать**:
- Отправка email (дубликаты некритичны, можем обработать)
- События пользователя
- Большинство production систем

### 3. Ровно один раз (exactly-once)

**Определение**: Каждое сообщение доставляется ровно один раз. Нет потерь, нет дубликатов.

**Как достичь**:
```go
// Производитель
писатель := &kafka.Writer{
    Addr:       kafka.TCP("localhost:9092"),
    Topic:      "события",
    Acks:       -1, // все синхронизированные копии
    Idempotent: true, // КЛЮЧЕВАЯ ОПЦИЯ!
}

// Потребитель
читатель := kafka.NewReader(kafka.ReaderConfig{
    GroupID: "группа1",
    // CommitInterval: 0, // ОТКЛЮЧИТЬ автофиксирование
})

for {
    сообщение, ошибка := читатель.ReadMessage(ctx)
    
    // Обрабатываем и ГАРАНТИРОВАННО сохраняем в БД
    результат := обработатьИСохранитьСообщение(сообщение)
    
    // Фиксируем смещение ТОЛЬКО если обработка успешна
    if результат.Успех {
        читатель.CommitMessages(ctx, сообщение)
    }
}
```

**Гарантии**:
- Идемпотентность производителя гарантирует: один раз отправлено = один раз в Kafka
- Ручное фиксирование гарантирует: обработано = только потом фиксирование смещения
- Результат: Ровно один раз per раздел, per производитель, per группа потребителей

**Где это использовать**:
- Платежные системы (ДЕНЬГИ нельзя потерять!)
- Финансовые операции
- Критичный бизнес-логик

**На собеседовании**:
> "Это самое дорогое по latency и пропускной способности, но единственный вариант для денег."

## Координация производителя и потребителя
---

Даже с ровно один раз возможны граничные случаи. Главное — **идемпотентность**:

```
Попытка 1:
├─ Производитель отправил сообщение в Kafka ✓
├─ Потребитель прочитал и обработал ✓
├─ Потребитель фиксирует смещение...
└─ КРЭШ перед фиксированием ❌

Попытка 2 (после перезагрузки):
├─ Потребитель начинает с того же смещения (не было зафиксировано)
├─ Прочитал то же сообщение
├─ Обработал то же сообщение (ИДЕМПОТЕНТНО)
├─ Сохранил то же изменение в БД (это OK если идемпотентно!)
└─ Фиксирует смещение ✓
```

**Ключ**: Приложение должно быть идемпотентным. Обработка одного сообщения дважды = как одна обработка.

## Семантический жаргон
---

| Гарантия | Потеря | Дубликаты | Сложность | Latency |
|----------|--------|-----------|-----------|---------|
| Максимум один раз | ✅ Возможна | ❌ Нет | Низкая | Низкий |
| Минимум один раз | ❌ Нет | ✅ Возможны | Средняя | Средний |
| Ровно один раз | ❌ Нет | ❌ Нет | Высокая | Высокий |

## Типичные вопросы собеседования
---

**В: Как я узнаю если потерял сообщение?**
О: В production мониторьте отставание потребителя. Если оно растет неожиданно, могла произойти потеря. Или сравните количество на производителе и потребителе.

**В: Можно ли получить ровно один раз без ручного фиксирования?**
О: Нет. Автофиксирование может фиксировать ДО обработки. Нужен явный контроль.

**В: Что если мой обработатьСообщение() идемпотентен но запись в БД, и запись дублируется?**
О: Используйте уникальный индекс в БД:
```sql
CREATE UNIQUE INDEX ON обработанные_сообщения(идентификатор_сообщения)
```
Дублирующаяся вставка вызовет ошибку, которую мы можем перехватить.

**В: Acks=all дает ровно один раз?**
О: Нет. Acks=all + идемпотентный производитель дает ровно один раз на стороне производителя, но потребителю нужно ручное фиксирование. Оба нужны.

---

**[← Назад к Kafka](../)**